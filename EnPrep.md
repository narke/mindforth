ConJoin EnBoot EnParser EnVocab

### Trajectory ###

The earliest AI Minds exist on a trajectory of development from having at first no prepositions in the EnBoot bootstrap sequence, to having only a few token prepositions for purposes of coding a rudimentary EnPrep module, to a target condition of knowing and recognizing all prepositions found and used in the English language.

### Deviation ###

Of necessity, MentiFex-class [AI Minds](http://aimind-i.com) deviate from the ideal of building artificial minds which start out like a human baby with no knowledge of prepositions and which learn the various prepositions of the natural language to which they are exposed immersively. Because each MentiFex AI Mind is software serving as a proof-of-concept for how artificial intelligence can be built in the first place, we skip the stage of ideal infancy and we try to demonstrate thinking in English as if the artificial person began life already at "childhood's end".

### Synergy ###

The EnPrep module cooperates with the other [mind-modules](http://mind.sourceforge.net/aisteps.html) in a mutual dependency which may not be immediately obvious. Since prepositions may take a noun or a [pronoun](http://code.google.com/p/mindforth/wiki/EnPronoun) just as a verb takes a noun or a pronoun, a fully developed EnPrep module will be helpful to the EnParser module which must determine whether an incoming word is a verb or a preposition. Once the AI Minds know all the prepositions in the English language, it will become easier for the AI software to identify prepositional phrases and not make the mistake of trying to [parse](http://code.google.com/p/mindforth/wiki/EnParser) a preposition as a verb leading to a direct object. This consideration encourages the builders and maintainers of AI Minds to work preferably with a 64-bit platform rather than a 32-bit platform, because the 64-bit AI software can grow immensely large and have enough room in memory to accommodate not only all the prepositions in the language, but indeed all the words known to exist in the English language.

### German ###

The basic EnPrep module gets more complicated for the [Wotan German AI](http://www.scn.org/~mentifex/DeKi.txt). Some prepositions in German must be followed by a particular case for the object of the preposition, and other prepositions permit different cases depending on whether physical motion is occurring. To a great extent, and more so than in English, German permits the substitution of _da_-compounds to replace a prepositional phrase, as English does with words like _therein_ and _thereof_. The software of the module will need to accommodate the variations in both German and English.

### Invocation ###

The conceptual activation of a preposition shall trigger the calling of the EnPrep module. It may be helpful to think of EnPrep as always ready to spring into action, but only upon reaching an activational threshold. It may also be helpful to think of a preposition as explaining the relationship between two nouns, such as "box on table" or "box under table".

### Saturation ###

If the AI being coded has a 64-bit capacity, it may be advantageous to include even archaic or unconventional (e.g., "upside the head") prepositions in the EnBoot or other bootstrap sequence, so that an AI destined for SuperIntelligence will not be puzzled or stumped by the input of an unusual preposition.